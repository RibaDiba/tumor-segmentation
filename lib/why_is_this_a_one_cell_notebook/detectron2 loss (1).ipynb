{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# run this only if setup is not complete \n",
    "import os\n",
    "os.chdir('../lib')\n",
    "import importlib, setup_coco_json, process_coco_json\n",
    "\n",
    "importlib.reload(setup_coco_json)\n",
    "importlib.reload(process_coco_json)\n",
    "\n",
    "from setup_coco_json import setup_rgb, setup_grayscale, setup_rgbd\n",
    "from process_coco_json import get_coco_rgb, get_coco_grayscale, get_coco_rgbd\n",
    "\n",
    "os.chdir('../data')\n",
    "setup_rgb('./useable_data', coco_json_dir='./coco_json', per_train=70, per_val=15, per_test=15)\n",
    "get_coco_rgb(\"./coco_json/rgb/\")\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"../data/coco_json/rgb/train/images/train.json\", \"../data/coco_json/rgb/train/images/\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"../data/coco_json/rgb/val/images/val.json\", \"../data/coco_json/rgb/val/images/\")\n",
    "register_coco_instances(\"my_dataset_test\", {}, \"../data/coco_json/rgb/test/images/test.json\", \"../data/coco_json/rgb/test/images/\")\n",
    "\n",
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "train_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
    "val_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")\n",
    "\n",
    "test_metadata = MetadataCatalog.get(\"my_dataset_test\")\n",
    "test_dataset_dicts = DatasetCatalog.get(\"my_dataset_test\")\n",
    "\n",
    "mask_folder = \"../data/coco_json/rgb/train/masks/Tumor\"  # Update with your binary mask folder path\n",
    "\n",
    "for d in random.sample(train_dataset_dicts, 1):\n",
    "   \n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "\n",
    "    print(f\"Image file: {d['file_name']}\")\n",
    "    \n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Failed to load image: {d['file_name']}\")\n",
    "        continue\n",
    "\n",
    "    #image annotations\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "\n",
    "    # Display the annotated image\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    plt.title(\"Image with Annotations\")\n",
    "\n",
    "    # Load the corresponding binary mask\n",
    "    image_base_name = os.path.basename(d[\"file_name\"]).split(\".\")[0]  # Get base name of the image\n",
    "    mask_path = os.path.join(mask_folder, f\"{image_base_name}.png\")  # Assuming masks have .png extension\n",
    "\n",
    "    print(f\"Mask file: {mask_path}\")\n",
    "    \n",
    "    # Load the binary mask\n",
    "    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if the mask was successfully loaded\n",
    "    if mask_img is None:\n",
    "        print(f\"Failed to load mask: {mask_path}\")\n",
    "        continue\n",
    "\n",
    "    # Display the binary mask\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
    "    plt.imshow(mask_img, cmap=\"gray\")\n",
    "    plt.title(\"Binary Mask\")\n",
    "\n",
    "    plt.show()  # Display the images side by side\n",
    "\n",
    "# Custom segmentation overlap loss function\n",
    "def compute_segmentation_overlap_loss(pred_masks, target_masks):\n",
    "    intersection = np.logical_and(pred_masks, target_masks)\n",
    "    union = np.logical_or(pred_masks, target_masks)\n",
    "    \n",
    "    # Compute IoU\n",
    "    iou = np.sum(intersection) / (np.sum(union) + 1e-6)  # Adding a small constant to avoid division by zero\n",
    "    return 1 - iou  # Return the overlap loss (1 - IoU)\n",
    "\n",
    "# Custom trainer with overlap loss\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    def build_loss(self, outputs, targets):\n",
    "        losses = super().build_loss(outputs, targets)\n",
    "        \n",
    "        # Assuming `outputs` contains predicted masks and `targets` contains ground truth masks\n",
    "        pred_masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "        target_masks = targets['instances'].gt_masks.cpu().numpy()\n",
    "        \n",
    "        # Compute segmentation overlap loss\n",
    "        overlap_loss = compute_segmentation_overlap_loss(pred_masks, target_masks)\n",
    "        \n",
    "        # Add the overlap loss to the existing losses\n",
    "        losses['segmentation_overlap_loss'] = overlap_loss\n",
    "        return losses\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (tumor)\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Use CustomTrainer\n",
    "trainer = CustomTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "\n",
    "# Function to display the original image with annotations and the predicted image\n",
    "def display_original_and_prediction_with_annotations(val_dataset_dicts, predictor, val_metadata):\n",
    "    for d in random.sample(val_dataset_dicts, 1):  # Select number of images for display\n",
    "        im = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(im)\n",
    "        \n",
    "        # Create a visualizer object for the original image with annotations\n",
    "        v_gt = Visualizer(im[:, :, ::-1],\n",
    "                          metadata=val_metadata,\n",
    "                          scale=0.5\n",
    "        )\n",
    "        out_gt = v_gt.draw_dataset_dict(d)\n",
    "        \n",
    "        # Create a visualizer object for the predicted image\n",
    "        v_pred = Visualizer(im[:, :, ::-1],\n",
    "                            metadata=val_metadata,\n",
    "                            scale=0.5,\n",
    "                            instance_mode=ColorMode.IMAGE_BW  # Remove the colors of unsegmented pixels\n",
    "        )\n",
    "        out_pred = v_pred.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        # Set up subplots\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(30, 30))\n",
    "        \n",
    "        # Display the original image with annotations\n",
    "        ax[0].imshow(out_gt.get_image()[:, :, ::-1])\n",
    "        ax[0].set_title('Original Image with Annotations', fontsize=24)\n",
    "        \n",
    "        # Display the predicted image\n",
    "        ax[1].imshow(out_pred.get_image()[:, :, ::-1])\n",
    "        ax[1].set_title('Predicted Image', fontsize=24)\n",
    "\n",
    "        for a in ax:\n",
    "            a.axis(\"off\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# test usage\n",
    "predictor = DefaultPredictor(cfg)\n",
    "display_original_and_prediction_with_annotations(test_dataset_dicts, predictor, test_metadata)\n",
    "\n",
    "def save_all_images(val_dataset_dicts, predictor, val_metadata, output_dir):\n",
    "    \n",
    "    # Create image path if it doesn't exist \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for i, d in enumerate(val_dataset_dicts):\n",
    "\n",
    "        im = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(im)\n",
    "        \n",
    "        v_gt = Visualizer(im[:, :, ::-1], metadata=val_metadata, scale=0.5)\n",
    "        out_gt = v_gt.draw_dataset_dict(d)\n",
    "        \n",
    "        v_pred = Visualizer(im[:, :, ::-1], metadata=val_metadata, scale=0.5, instance_mode=ColorMode.IMAGE_BW)\n",
    "        out_pred = v_pred.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, figsize=(30, 30))\n",
    "        \n",
    "        ax[0].imshow(out_gt.get_image()[:, :, ::-1])\n",
    "        ax[0].set_title('Original Image with Annotations', fontsize=24)\n",
    "        \n",
    "        ax[1].imshow(out_pred.get_image()[:, :, ::-1])\n",
    "        ax[1].imshow(out_pred.get_image()[:, :, ::-1])\n",
    "        ax[1].set_title('Predicted Image', fontsize=24)\n",
    "\n",
    "        for a in ax:\n",
    "            a.axis(\"off\")\n",
    "\n",
    "        # Save the plot to the specified output directory\n",
    "        save_path = os.path.join(output_dir, f\"comparison_{i}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Saved comparison image to {save_path}\")\n",
    "\n",
    " save all validation set images\n",
    "output_dir = \"./output_images\"\n",
    "save_all_images(test_dataset_dicts, predictor, test_metadata, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
